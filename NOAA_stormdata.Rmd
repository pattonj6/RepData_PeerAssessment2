---
title: "NOAA Stormdata Tracking between 1950-2011"
output: 
  html_document:
    keep_md: true
---

## Synopsis

In this report we are analyzing the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm database.  The database has tracking for events in the US 50 states as well as 22 other locations like US territorities  (e.g. Guam, American Samoa).  Tornados, heat, and wind are the top 3 events that measured the highest number of combined injuries + fatalities.  We combined injuries and fatalities into a single metric to determine the ranking.  Extreme heat-related events appear to 

## Loading and Processing the Data

```{r, echo=TRUE}
library(lubridate)
library(ggplot2)
library(dplyr)
library(data.table)
library(tidyr)
library(knitr)
## loading for US State Facts and Figures
library(datasets)

## output wider graphs
opts_chunk$set(out.width='750px', dpi=200)

if (!file.exists("./data")) {
    dir.create("./data")
}
```

Download, unzip, and read in the data.  This was done on Windows7 OS, so downloaded in 'wb' mode.

```{r, echo=TRUE}
fileurl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileurl, destfile = "./data/repdata%2Fdata%2FStormData.csv.bz2", mode = 'wb')

data <- read.csv("./data/repdata%2Fdata%2FStormData.csv.bz2", stringsAsFactors = FALSE)
```

Take a preliminary look at the data.

```{r, echo=TRUE}
str(data)
head(data)
summary(data)
```

This was moderately helpful, we are interested in health and economic impacts by events.  I see the columns of interest.

Let's start to explore the data in the columns, here are some basic questions I have.

```{r, echo=TRUE}
length(unique(data$EVTYPE)) -> disaster.type.count
range(data$FATALITIES) -> max.death.count
range(data$INJURIES) -> max.injury.count

length(unique(data$STATE)) -> states.impacted.count
unique(data$STATE) -> states.impacted
setdiff(states.impacted, state.abb) -> impacted.outside.50.states
```

There are 22 locations outside the US 50 states that are included in this data set.  I see Guam, Puerto Rico, Virgin Islands....several others I don't recognize, immediately.  For this analysis we are asked to look at just the United States, which means I will need to remove all of the extra locations in the data, rather than filter just for U.S.  "DC" appears to be Washington, DC, so I will include that one.

convert from data.frame to my preferred data.table.

```{r, echo=TRUE}
dt_data <- data.table(data)

## check for NA values
na.rows.injuries <- sum(is.na(dt_data$INJURIES))
na.rows.deaths <- sum(is.na(dt_data$FATALITIES))
```

There are no NA rows....good!

## Health impact analysis

Calculate: 
--Remove non-US states.  Keep Washington, DC.
--The total sum and averages of deaths and injuries by event type.
--Also calculate a total sum of fatal+injure by event type.

```{r, echo=TRUE}
impacted.outside.50.states.no.DC <- impacted.outside.50.states[!impacted.outside.50.states %in% 
                                                 "DC"]

dt_data_nonUS_removed <- dt_data[which(!dt_data$STATE %in% 
                                           impacted.outside.50.states.no.DC),]

dt_data_sums <- dt_data_nonUS_removed[ ,.(sum.fatalities=sum(FATALITIES), avg.fatalities=mean(FATALITIES),
                                          sum.injuries=sum(INJURIES), avg.injuries=mean(INJURIES),
                                          sum.fatal.or.injure=sum(FATALITIES,INJURIES)),
                                       by=EVTYPE][order(-sum.fatal.or.injure)][sum.fatal.or.injure >= 100]
```

I filtered out rows of data < 100 combined injuries or fatalities.  There are misspelled EVTYPE labels 
and lables that don't all fit into 1 common heading, so end up as a separate observation with 
no injuries or fatalities.  A perfect data set would combine in these misspelled EVTYPE labels
and other categories so that averages are correctly counted.  I am going to ignore this consolidation work
for this exercise.

Let's take a look at the sum.fatal.or.injure in dot plot format.  I chose this since EVTYPE is a long discrete list, and I want to see the overall ranking in easy-to-read labels.

```{r, echo=TRUE}
a <- ggplot(dt_data_sums, aes(log(sum.fatal.or.injure), reorder(EVTYPE,sum.fatal.or.injure))) +
                geom_point(size=3)
print(a)
```

Tornado (by 2.5x orders of magnitude), Excessive Heat, and TSTM Wind are the top 3 injury and fatality events, since 1950.  I'd like to plot all of the injury, fatality, and average data on the same plot, so I need to tidy the data.  Data is ordered by sum.fatal.or.injure.  I know it is going to deprecate my duplicate levels, this is ok for this plot.

```{r, echo=TRUE}
dt_data_sums %>% gather(type, count, -EVTYPE) -> tidy.data
nameorder <- tidy.data$EVTYPE[order(tidy.data[which(tidy.data$type == "sum.fatal.or.injure"),])]
tidy.data$EVTYPE <- factor(tidy.data$EVTYPE, levels = nameorder)
```

```{r, echo=TRUE}
b <- ggplot(tidy.data, aes(count, EVTYPE)) + 
    geom_point(size=4, aes(colour=type)) +
    scale_x_log10() +
    ggtitle("storm event versus injury/fatality")
print(b)
```

I love this dot plot!  Clearly, tornado by itself is on top for the total historical sum.fatal.or.injure metric.  However, if you study the avg.injuries(blue) and avg.fatalities(green) dots you'll see that all "heat" categories and hurricane/typhoon stand out above the baseline data.  ("Glaze"" and "Wild Fires" also show elevated levels from baseline, but further down the chart.) This means that on average, when these events occur, they injure or kill more people than even tornados.  But since 1950, tornados have injured or killed a larger total, likely do to a few signficantly bad events.

Top priority would be placed on tornados, heat, and hurricane/typhoons.  I suspect heat would jump to the top of the list if we combined all 4 "heat" categories into a single line item.  (If I wasn't limited to 3 figures I would do this analysis!)

## Economic Impact Analysis

Calculate:
--Total sum and average values using PROPDMG and CROPDMG columns by event type.  Even though CROPDMG is a separate column, I still consider it a direct economic impact event and can be combined with PROPDMG to examine overall economic impact. 
--Remove non-US states and rows with incorrect "EXP" sympols or values.

```{r, echo=TRUE}
range(dt_data_nonUS_removed$PROPDMG) -> prop.damage.range
unique(dt_data_nonUS_removed$PROPDMGEXP) -> prop.damage.exp
range(dt_data_nonUS_removed$CROPDMG) -> crop.damage.range
unique(dt_data_nonUS_removed$CROPDMGEXP) -> crop.damage.exp
```

The exponent column is supposed to just have "B", "M", "K", or "H".  I'd like to do a quick
check on a few rows with the other values to figure out why they are there.

```{r, echo=TRUE}
dt_data_rows_wrong_exp <- dt_data_nonUS_removed[which(dt_data_nonUS_removed$PROPDMGEXP %in% 
                                            c("+", "5", "6", "?", "4", "2", "3", "7", "-")),]
```

Is there a notes section at the bottom of the data?  Why are numbers in the EXP column?

```{r, echo=TRUE}
tail(dt_data_nonUS_removed$PROPDMGEXP)
identical(crop.damage.exp, prop.damage.exp)
identical(dt_data_nonUS_removed$CROPDMGEXP, dt_data_nonUS_removed$PROPDMGEXP)
```

The remarks column has some notes on total damage estimates that sort of match up with the
numbers in the EXP columns, but this only happens on a few of them.  It appears these numeric values are due to rounding not to 3 significant figures, or just incorrect input of data.  

How many rows are like this?

```{r, echo=TRUE}
print(prop.damage.exp)
print(crop.damage.exp)
prop.damage.exp.incorrect <- prop.damage.exp[!prop.damage.exp %in% 
                                                 c("K","M","B","m","h","H", "", "0")]

crop.damage.exp.incorrect <- crop.damage.exp[!crop.damage.exp %in% 
                                                 c("k","K","M","B","m","h","H", "", "0")]

nrow(dt_data_nonUS_removed[which(dt_data_nonUS_removed$PROPDMGEXP %in% 
                                                            prop.damage.exp.incorrect),])
nrow(dt_data_nonUS_removed[which(dt_data_nonUS_removed$CROPDMGEXP %in% 
                                                            crop.damage.exp.incorrect),])
```

98+8 rows with incorrect EXP values....ok, not many.  I am going to remove them from the analysis.

Now I am going to filter out the rows that contain incorrect "EXP" values.
Go back to original dt_data.

```{r, echo=TRUE}
dt_data_w_exp_rows_removed <- dt_data_nonUS_removed[which(!dt_data_nonUS_removed$PROPDMGEXP %in% 
                                           prop.damage.exp.incorrect),]
dt_data_w_exp_rows_removed <- dt_data_w_exp_rows_removed[which
                                            (!dt_data_w_exp_rows_removed$CROPDMGEXP %in% 
                                                crop.damage.exp.incorrect),]

print(unique(dt_data_w_exp_rows_removed$PROPDMGEXP))
print(unique(dt_data_w_exp_rows_removed$CROPDMGEXP))
```

OK, good, we removed the rows with incorrect "EXP" values. Now, create a function to translate character mulitpliers into numeric.

```{r, echo=TRUE}
exp.magnitude <- function(x) {
    ifelse(x == "K", 10^3,
    ifelse(x == "M", 10^6,
    ifelse(x == "" , 1,
    ifelse(x == "B", 10^9,
    ifelse(x == "m", 10^6,
    ifelse(x == "0" , 1,
    ifelse(x == "h", 10^2,
    ifelse(x == "H", 10^2, NA))))))))
}
```

Create the new columns with numeric multiplier, execute the multiplication, create a prop+crop summary column.

```{r, echo=TRUE}
dt_data_w_exp_rows_removed[ , prop.damage.multiplier := exp.magnitude(PROPDMGEXP)]
dt_data_w_exp_rows_removed[ , crop.damage.multiplier := exp.magnitude(CROPDMGEXP)]

dt_data_w_exp_rows_removed[ , prop.damage.total := prop.damage.multiplier*PROPDMG]
dt_data_w_exp_rows_removed[ , crop.damage.total := crop.damage.multiplier*CROPDMG]
dt_data_w_exp_rows_removed[ , damage.total := prop.damage.total+crop.damage.total]
```

Now generate the statistics.  Sum and averages for property and crop, plus sum/averages for prop+crop, all by event type.  Since I am plotting on a dot plot, I filtered out rows to make the plot readable.

```{r, echo=TRUE}
dt_data_econ <- dt_data_w_exp_rows_removed[ ,.(sum.property=sum(prop.damage.total), 
                                               avg.property=mean(prop.damage.total), 
                                         sum.crop=sum(crop.damage.total), 
                                         avg.crop=mean(crop.damage.total), 
                                         sum.prop.and.crop=sum(damage.total)),
                                      by=EVTYPE][order(-sum.prop.and.crop)][sum.prop.and.crop >100000000]
```

I'd like to plot all of the property, crop, and combined data on the same plot, so I need to tidy the data.  Data is ordered by sum.prop.or.crop.  I know it is going to deprecate my duplicate levels, this is ok for this plot.

```{r, echo=TRUE}
dt_data_econ %>% gather(type, count, -EVTYPE) -> tidy.econ.data
nameorder <- tidy.econ.data$EVTYPE[order(tidy.econ.data[which(tidy.econ.data$type == "sum.prop.and.crop"),])]
tidy.econ.data$EVTYPE <- factor(tidy.econ.data$EVTYPE, levels = nameorder)
```

```{r, echo=TRUE}
b <- ggplot(tidy.econ.data, aes(count, EVTYPE)) + 
    geom_point(size=4, aes(colour=type)) +
    scale_x_log10() + 
    xlab("US dollar amount") +
    ggtitle("storm event vs. property/crop damage loss ($)")
print(b)
```

Top 3 for economic impact are flood, hurrican/typhoon, and tornado.  Interesting to note that the majority of economic loss is in property, evidenced by the overlap of red(sum.property) and pink(sum.prop.and.crop) datapoints for most events.  Temperature related events (drought, extreme heat/cold, frost) all show higher crop damage than property damage - this intuitively makes sense.  The catastropic events like flood, hurricane/typhoon, tornados are the ones that cause large property damage.
